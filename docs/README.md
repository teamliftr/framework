# Home

## Introduction

*TeamLiftr is an assessment and performance tracking framework that provides a structured, straightforward way for software product teams to assess their own performance. Teams can use the framework to efficiently identify which work areas they feel should be prioritized for improvement.*

We developed TeamLiftr to meet our own need for a framework that offers a high-level overview of team performance. Teams we work with have been able to use the framework to identify improvement opportunities they would otherwise miss, and have found it to simplify the process of selecting and onboarding new improvement projects. 

The framework's design and content reflect current best practices in software engineering and assessment design, and the framework as a whole has been validated by outside exports. While the framework aims to be comprehensive, it is ultimately a subjective and non-exhaustive document that reflects the perspectives of its creators. 

This “curatorial” approach to creating TeamLiftr separates it from frameworks that are based on survey or interview feedback. These approaches are valuable, but they also pass-on any feedback blindspots. Our approach allows us to ensure that we address important areas that survey-based methods could miss.

The TeamLiftr framework is complemented by the TeamLiftr app (TeamLiftr.com). The app includes all three TeamLiftr assessments, visualizations of both individual and team-level assessment feedback, progress tracking tools, and dedicated collaborative workspaces for each of your team’s improvement projects. 

The framework itself will always be free. The app provides an optional way for teams to keep their entire improvement journey within a single platform so that their improvement workflows are more streamlined, trackable, and transparent.

## The framework's structure
TeamLiftr’s assessment framework consists of three assessments, each with four categories, each with six topics (for a total of 72 topics). The authors have chosen to limit the number of topics to 72 in order to keep the scope manageable and easy to follow, while remaining comprehensive. The framework’s symmetrical 3x4x6 structure allows users to advance through the assessments and categories in any order they desire; in lieu of completing an entire assessment at once, many users opt to complete the assessments in chunks, one category at a time.  

The three main assessment categories are:

**Product & Technology**      
A comprehensive product strategy isn’t necessary to develop a working product, but it is necessary to develop a product that’s competitive and sustainable. This assessment helps teams to identify what product features to prioritize and how to maximize value for end-users. 

**People & Performance**     
A strong product needs a strong team. This assessment is designed to help teams to foster an inclusive culture that values and prioritizes collaboration and continuous improvement. Every project’s performance depends on its people, and every team’s competitiveness depends on its ability to help its people improve. 

**Operations & Risk Management**     
It’s impossible to control the unexpected, but it’s not impossible to prepare for it. This assessment is designed to help teams identify whether it’s taking the necessary steps to prevent and recover from operational disruptions. Your product’s success depends on your team’s ability to prevent disruptions from occurring (and on its ability to recover when those disruptions happen anyway).

Each topic in the framework consists of a statement for the user to evaluate and an explanation that provides further detail on the topic. For example, this is the first topic in the Product Strategy category, which is part of the Product & Technology assessment:

**1.1.1 Product Vision**
   - **Statement:** Your team has an explicit, high-level vision for the product(s) and/or service(s) it is responsible for. This vision clearly describes the problem that the product/service aims to solve, and was developed as a collaborative effort.**
   - **Explanation:** A strong product vision emphasizes the value the product offers to users, and in-turn provides all team members with a shared understanding of the team’s long-term goal. Product visions should be validated by both team members and potential users, and revised as-needed to ensure development stays focused on creating a product that addresses a genuine customer need.

Users complete each topic by scoring their level of agreement with that topic's statement. The scoring system is designed to use the following format: 1 - *Untrue*, 
2 - *Somewhat True*, 3 - *Mostly True*, 4 - *Entirely True*

## The TeamLiftr Framework
Selecting any individual category 

**[1. Product & Technology](product_and_technology/README.md)**
   - [1.1 Product Strategy](product_and_technology/PRODUCT_STRATEGY.md)
   - [1.2 Technology Strategy](product_and_technology/TECHNOLOGY_STRATEGY.md)
   - [1.3 Continuous Integration & Deployment](product_and_technology/CONTINUOUS_INTEGRATION_AND_DEPLOYMENT.md)
   - [1.4 Data-Driven Development](product_and_technology/DATA-DRIVEN_DEVELOPMENT.md)

**[2. People & Performance](people_and_performance/README.md)**
   - [2.1 Current Performance](people_and_performance/CURRENT_PERFORMANCE.md)
   - [2.2 Continuous Improvement](people_and_performance/CONTINUOUS_IMPROVEMENT.md)
   - [2.3 Workplace Culture](people_and_performance/WORKPLACE_CULTURE.md)
   - [2.4 Talent Recruitment & Development](people_and_performance/TALENT_RECRUITMENT_AND_DEVELOPMENT.md)

**[3. Operations & Risk Management](operations_and_risk_management/README.md)**
   - [3.1 Daily Operations](operations_and_risk_management/DAILY_OPERATIONS.md)
   - [3.2 Quality Assurance & Standardization](operations_and_risk_management/QUALITY_ASSURANCE_AND_STANDARDIZATION.md)
   - [3.3 Continuity & Incident Management](operations_and_risk_management/CONTINUITY_AND_INCIDENT_MANAGEMENT.md)
   - [3.4 Information Security Assurance](operations_and_risk_management/INFORMATION_SECURITY_ASSURANCE.md)

## How to use with your team
TeamLiftr is designed to foster continuous improvement through a cyclical process: Teams assess their performance, identify what issues to improve, and initialize an improvement project for those issues. Teams then use the framework to reassess their performance periodically, both to evaluate their current progress and to identify new priorities for improvement. 

The TeamLiftr in a nutshell: Assess Performance → Identify Improvement Priority → Create Improvement Project → (Re)assess Performance.

To get started, teams should complete at least part of our assessments—as noted above, both the assessments and their individual categories can be completed in any order. After completing an assessment, teams should discuss their results together in order to identify improvement priorities. 

In order to make it easier for teams to identify their improvement priorities, TeamLiftr organizes the topics in each category according to their immediate importance: 

   - **Topics 1-3** in each category are “Basic” performance topics—core performance issues that teams should prioritize first. 
   - **Topics 4-5** are “Intermediate” and Topic 6 is an “Advanced” topic—these issues are for teams that are ready to optimize their performance and out-compete their peers. 

After using an assessment to identify a particular area to improve performance, teams should start an improvement initiative for that topic. Because that initiative is linked to a specific topic from an assessment, your team will be able to monitor its success by tracking how feedback changes over time. 

This is why it’s beneficial for teams to retake assessments periodically: Using the assessments to create an ongoing record of the team’s feedback makes it possible for teams to easily and accurately monitor changes in performance over time, across all the major variables that affect their ultimate performance.

### Getting the most out of post-assessment discussions <!-- Revisit this section. Make more concise? -->
The discussion portion of the TeamLiftr framework is just as important as the assessment itself. This is a time for team members to review results, share insights, and ultimately develop a plan of action for improvement. When used to their full potential, these post-assessement discussions can be an invaluable shared record of your team's performance improvement efforts.    
    
*Identify Potential Improvement Projects*   
Identifying which areas of your team’s performance should be prioritized can be challenging; however, the TeamLiftr framework makes this process far more straightforward. By breaking down your team’s performance into 12 categories of performance, with six topics per-category, TeamLiftr offers an organized, easy-to-discuss snapshot of team performance. The framework can’t tell your team what its specific goals should be, but it can provide the structure necessary to inspire teams to develop that answer for themselves. 

*Inspire Meaningful Discussions*     
TeamLiftr’s post-assessment discussions are an opportunity for individual team members to highlight issues they feel strongly about. Each topic is a potential “jumping off” point that team members can use to highlight a topic they feel deserves more awareness within the team. It can be difficult to direct a group’s attention to issues that they don’t view as important—these post-assessment discussions offer team members the agency to prevent key issues from being overlooked. 

*Facilitate Knowledge Sharing*   
Group discussion of assessment results should encourage the exchange of perspectives between team members and provide opportunities for team members to build shared knowledge about a topic. Knowledge sharing during discussions is an improvement activity unto itself; however, teams may decide that improving their knowledge of a specific topic area should be an improvement project in its own right. 

*Create Topic Breakdowns*   
TeamLiftr deals with performance at a relatively high-level. To fully discuss a topic from the framework, it will often be necessary to consider the various factors that affect your team’s performance in that area. This topic breakdown process is important when planning your improvement projects: the ability to target specific performance variables is a crucial part of goal-setting.

*Reinforce Existing Achievements*   
When teams periodically update their TeamLiftr assessments, their subsequent post-assessment discussions can act as a valuable knowledge management activity. Team discussions about changes in assessment results are an effective way to identify if refresher training is necessary or if there has been a breakdown in skill transfer somewhere. These activities can ensure that your team’s performance improvement achievements are explicitly logged and retained long-term.

## Ambitions / Future Additions to the Framework
**Suggested Metrics**      
We are currently developing a suite of suggested metrics for the framework. Each metric will be linked to a specific topic in the framework, and is designed as a way for teams to measure the progress of their improvement projects.        
        
These metrics will make it easier for teams to assess the effects of their improvement efforts with confidence—and when teams have concrete “proof” that their efforts are having a positive effect, they are more likely to stay committed to them long-term.        
           
Providing suggested metrics should also make the framework more actionable: The “action threshold” for starting a new improvement project should be lower if teams know that they don’t have to worry about developing their own KPI, and can instead rely on using a TeamLiftr-validated performance metric to assess their progress.       
            
**Usage Standards & Guidance**        
We are investigating whether the creation of a formal set of usage guidelines would be beneficial to our users. These usage guidelines would collectively serve as a flexible standard that teams could use to guide their ongoing, long-term use of the framework.          
           
This usage guidance would be focused on high-level activities, such as: engaging with assessments, performing team reviews, selecting improvement priorities, creating new improvement projects, etc.            
              
Teams often have trouble assessing whether they are doing “enough” when pursuing their improvement goals, and this uncertainty can negatively impact motivation. By enabling teams to assess their overall use of the framework against a set of TeamLiftr-validated guidelines, we can provide teams with the ability to more confidently assess whether their current efforts are in-line with their goals.            
               
## Contributing
TeamLiftr’s commitment to continuous improvement extends to the framework itself—we’re always looking to make TeamLiftr better, and want it to be as useful as possible for product engineering teams. If you’d like to help with the development of TeamLiftr, we’d love to hear from you. Here are some ways to get involved:

   - **Provide Feedback** by opening an issue in our GitHub repository
   - **Propose a Change** by submitting a pull request 
   - **Join Our Community** by signing up to our Slack Channel **[TBD]**

## FAQs
[To be written]

## License
TeamLiftr’s authors are Floris Vlasveld and Jeffrey Cusack.     
      
The TeamLiftr Framework and its associated assets are copyright Inspire Innovation BV, all rights reserved. Associated assets include but are not limited to text and images.      
       
The TeamLiftr Framework is free for personal and non-commercial use and can be used without permission. Express written consent must be obtained for all other uses. 

